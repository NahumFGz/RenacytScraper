{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path, extension):\n",
    "    dir_name  = os.path.join(os.getcwd(), path)\n",
    "    files     = os.listdir(dir_name)\n",
    "    \n",
    "    paths    = []\n",
    "    for file in files:\n",
    "        if extension in file:\n",
    "            paths.append(os.path.join(path,file))\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Lista de todos los investigadores de renacyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Leer los jsons y guardarlos en un dataframe\n",
    "paths = get_files(os.path.join(os.getcwd(),'originals','renacyt','investigadores'), '.json')\n",
    "df_renacyt = pd.concat([pd.read_json(path) for path in paths], axis=0)\n",
    "df_renacyt = df_renacyt.sort_values(by=['ctiVitae'])\n",
    "\n",
    "df_renacyt.to_parquet(os.path.join(os.getcwd(),'processed','parquet','01_lista_investigadores_renacyt.parquet'))\n",
    "df_renacyt.astype(str).to_excel(os.path.join(os.getcwd(),'processed','excel','01_lista_investigadores_renacyt.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Perfiles de investtigadores de renacyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Leer los jsons y guardarlos en un dataframe\n",
    "paths = get_files(os.path.join(os.getcwd(),'originals','renacyt','perfil','1_datos_investigador'), '.json')\n",
    "path = paths[0]\n",
    "path.split('_')[-2]\n",
    "\n",
    "# 2. Iterar sobre cada path\n",
    "formaciones_list = []\n",
    "publicaciones_list = []\n",
    "patentes_list= []\n",
    "asesorias_list = []\n",
    "for path in paths:\n",
    "\n",
    "    # A. Obtener el orcid\n",
    "    orcid = path.split('_')[-2]\n",
    "    cti_vitae = path.split('_')[-3]\n",
    "\n",
    "    # B. Leer el json\n",
    "    with open(path, 'r') as archivo:\n",
    "        data = json.load(archivo)\n",
    "\n",
    "    # C. Obtener los datos de formación académica    \n",
    "    formaciones = data[\"criterioARequest\"][\"formacionesAcademicas\"]\n",
    "    for formacion in formaciones:\n",
    "        data_format = eval( '[' + str(formacion[\"formacionAcademicaPOJO\"]) + ']') \n",
    "        df = pd.DataFrame(data_format)\n",
    "        df['cti_vitae'] = cti_vitae\n",
    "        df['orcid'] = orcid\n",
    "\n",
    "        formaciones_list.append(df)\n",
    "\n",
    "    # D. Obtener los datos de publicaciones\n",
    "    publicaciones = data[\"criterioBRequest\"][\"produccionesBibliograficas\"]\n",
    "    for publicacion in publicaciones:\n",
    "        data_format = eval( '[' + str(publicacion[\"produccionBibliograficaPOJO\"]) + ']') \n",
    "        df = pd.DataFrame(data_format)\n",
    "        df['cti_vitae'] = cti_vitae\n",
    "        df['orcid'] = orcid\n",
    "\n",
    "        publicaciones_list.append(df)\n",
    "\n",
    "    # E. Obtener los datos de patentes\n",
    "    patentes = data[\"criterioCRequest\"][\"derechosPropiedadesIntelectuales\"]\n",
    "    for patente in patentes:\n",
    "        data_format = eval( '[' + str(patente[\"derechoPropiedadIntelectualPOJO\"]) + ']') \n",
    "        df = pd.DataFrame(data_format)\n",
    "        df['cti_vitae'] = cti_vitae\n",
    "        df['orcid'] = orcid\n",
    "\n",
    "        patentes_list.append(df)\n",
    "\n",
    "    # F. Obtener asesorias de tesis\n",
    "    asesorias = data[\"criterioFRequest\"][\"datosLaborales\"]\n",
    "    for asesoria in asesorias:\n",
    "        data_format = eval( '[' + str(asesoria[\"datosLaboralesPOJO\"]) + ']') \n",
    "        df = pd.DataFrame(data_format)\n",
    "        df['cti_vitae'] = cti_vitae\n",
    "        df['orcid'] = orcid\n",
    "\n",
    "        asesorias_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Concatenar formaciones_list en df_formacione y guardar \n",
    "df_formacion = pd.concat(formaciones_list, axis=0)\n",
    "df_formacion.to_parquet(os.path.join(os.getcwd(),'processed','parquet','02_formaciones_academicas_renacyt.parquet'))\n",
    "df_formacion = df_formacion.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "df_formacion.astype(str).to_excel(os.path.join(os.getcwd(),'processed','excel','02_formaciones_academicas_renacyt.xlsx'), index=False)\n",
    "\n",
    "# 4. Concatenar publicaciones_list en df_publicaciones y guardar\n",
    "df_publicacion = pd.concat(publicaciones_list, axis=0)\n",
    "df_publicacion.to_parquet(os.path.join(os.getcwd(),'processed','parquet','03_publicaciones_renacyt.parquet'))\n",
    "df_publicacion = df_publicacion.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "df_publicacion.astype(str).to_excel(os.path.join(os.getcwd(),'processed','excel','03_publicaciones_renacyt.xlsx'), index=False)\n",
    "\n",
    "# 5. Concatenar patentes_list en df_patentes y guardar\n",
    "df_patente = pd.concat(patentes_list, axis=0)\n",
    "df_patente.to_parquet(os.path.join(os.getcwd(),'processed','parquet','04_patentes_renacyt.parquet'))\n",
    "df_patente = df_patente.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "df_patente.astype(str).to_excel(os.path.join(os.getcwd(),'processed','excel','04_patentes_renacyt.xlsx'), index=False)\n",
    "\n",
    "# 6. Concatenar asesorias_list en df_asesorias y guardar\n",
    "df_asesoria = pd.concat(asesorias_list, axis=0)\n",
    "df_asesoria.to_parquet(os.path.join(os.getcwd(),'processed','parquet','05_asesorias_renacyt.parquet'))\n",
    "df_asesoria = df_asesoria.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "df_asesoria.astype(str).to_excel(os.path.join(os.getcwd(),'processed','excel','05_asesorias_renacyt.xlsx'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Perfiles de ORCID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_trabajo(trabajo):\n",
    "    try:\n",
    "        doi = trabajo[\"externalIdentifiers\"][0][\"externalIdentifierId\"][\"value\"]\n",
    "    except:\n",
    "        doi = None\n",
    "    \n",
    "    try:\n",
    "        doi_url = trabajo[\"externalIdentifiers\"][0][\"url\"][\"value\"]\n",
    "    except:\n",
    "        doi_url = None\n",
    "\n",
    "    try:\n",
    "        publication_year = trabajo[\"works\"][0][\"publicationDate\"][\"year\"]\n",
    "    except:\n",
    "        publication_year = None\n",
    "\n",
    "    try:\n",
    "        publication_month = trabajo[\"works\"][0][\"publicationDate\"][\"month\"]\n",
    "    except:\n",
    "        publication_month = None\n",
    "\n",
    "    try:\n",
    "        publication_day = trabajo[\"works\"][0][\"publicationDate\"][\"day\"]\n",
    "    except:\n",
    "        publication_day = None\n",
    "\n",
    "    try:\n",
    "        source = trabajo[\"works\"][0][\"source\"]\n",
    "    except:\n",
    "        source = None\n",
    "\n",
    "    try:\n",
    "        source_name = trabajo[\"works\"][0][\"sourceName\"]\n",
    "    except:\n",
    "        source_name = None\n",
    "    \n",
    "    try:\n",
    "        title = trabajo[\"works\"][0][\"title\"][\"value\"]\n",
    "    except:\n",
    "        title = None\n",
    "\n",
    "    try:\n",
    "        journal_title = trabajo[\"works\"][0][\"journalTitle\"][\"value\"]\n",
    "    except:\n",
    "        journal_title = None\n",
    "\n",
    "    try:\n",
    "        work_type = trabajo[\"works\"][0][\"workType\"][\"value\"]\n",
    "    except:\n",
    "        work_type = None\n",
    "\n",
    "    try:\n",
    "        number_of_contributors = trabajo[\"works\"][0][\"numberOfContributors\"]\n",
    "    except:\n",
    "        number_of_contributors = None\n",
    "\n",
    "    return doi, doi_url, publication_year, publication_month, publication_day, source, source_name, title, journal_title, work_type, number_of_contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Leer los jsons y guardarlos en un dataframe\n",
    "paths = get_files(os.path.join(os.getcwd(),'originals','orcid','3_publicaciones'), '.json')\n",
    "path = paths[0]\n",
    "\n",
    "# 2. Iterar sobre cada path\n",
    "trabajos_list = []\n",
    "for path in paths:\n",
    "    # A. Obtener el orcid\n",
    "    orcid = path.split('_')[-2]\n",
    "    cti_vitae = path.split('_')[-3]\n",
    "\n",
    "    # B. Leer el json\n",
    "    with open(path, 'r') as archivo:\n",
    "        data = json.load(archivo)\n",
    "\n",
    "    # C. Procesar trabajos\n",
    "    trabajos = data['groups']\n",
    "\n",
    "    print(len(trabajos))\n",
    "    trabajo = trabajos[0]\n",
    "\n",
    "    for trabajo in trabajos:\n",
    "        \n",
    "        doi, doi_url, publication_year, publication_month, publication_day, source, source_name, title,journal_title, work_type, number_of_contributors = procesar_trabajo(trabajo)\n",
    "        \n",
    "        df_trabajos = pd.DataFrame({'doi': doi,\n",
    "                                    'doi_url': doi_url,\n",
    "                                    'publication_year': publication_year,\n",
    "                                    'publication_month': publication_month,\n",
    "                                    'publication_day': publication_day,\n",
    "                                    'source': source,\n",
    "                                    'source_name': source_name,\n",
    "                                    'title': title,\n",
    "                                    'journal_title': journal_title,\n",
    "                                    'work_type': work_type,\n",
    "                                    'number_of_contributors': number_of_contributors}, index=[0])\n",
    "        df_trabajos['cti_vitae'] = cti_vitae\n",
    "        df_trabajos['orcid'] = orcid\n",
    "\n",
    "        trabajos_list.append(df_trabajos)\n",
    "\n",
    "# 3. Concatenar trabajos_list en df_trabajos y guardar\n",
    "df_trabajo = pd.concat(trabajos_list, axis=0)\n",
    "df_trabajo.to_parquet(os.path.join(os.getcwd(),'processed','parquet','06_trabajos_orcid.parquet'))\n",
    "df_trabajo = df_trabajo.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "df_trabajo.astype(str).to_excel(os.path.join(os.getcwd(),'processed','excel','06_trabajos_orcid.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fin del procesamiento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proceso finalizado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
