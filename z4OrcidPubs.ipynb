{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTAMOS EN --->  darwin\n",
      "PROJECT_PATH:  /Users/nahumfg/Projects/GitHubProjects/RenacytScraper\n",
      "CHROME_DRIVER_PATH:  /Users/nahumfg/Projects/GitHubProjects/RenacytScraper/chromedriver/darwin/chromedriver\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## A. Librerias\n",
    "####################################\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.paths import CHROMEDRIVER_PATH, PROJECT_PATH\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "####################################\n",
    "## B. Funciones\n",
    "####################################\n",
    "\n",
    "def get_files(path, extension):\n",
    "    dir_name  = os.path.join(os.getcwd(), path)\n",
    "    files     = os.listdir(dir_name)\n",
    "    \n",
    "    paths    = []\n",
    "    for file in files:\n",
    "        if extension in file:\n",
    "            paths.append(os.path.join(path,file))\n",
    "\n",
    "    return paths\n",
    "\n",
    "def start_har(proxy, name):\n",
    "    options = {\n",
    "        'captureHeaders': True, \n",
    "        'captureContent': True, \n",
    "        'captureBinaryContent': True, \n",
    "        'captureCookies': True, \n",
    "        'captureHeadersSize': -1, \n",
    "        'captureMaxSize': -1, \n",
    "        'captureBinaryContentMaxLength': -1 # Tamaño máximo del contenido binario\n",
    "    }\n",
    "    proxy.new_har(name, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se eliminaron los archivos de la carpeta\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "## C. Ejecución\n",
    "########################\n",
    "\n",
    "# 1. Seleccionar modo\n",
    "HEADLESS = True\n",
    "PRINT_VIEW = False\n",
    "\n",
    "# 2. Eliminar todos los archivos de la carpeta\n",
    "try:\n",
    "    files = get_files(os.path.join(os.getcwd(),'outputs','jsons','orcid_title'), '.')\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "    print('Se eliminaron los archivos de la carpeta')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se generaron 6993 urls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://orcid.org/0000-0003-1583-7113',\n",
       " 'https://orcid.org/0000-0001-9740-5490',\n",
       " 'https://orcid.org/0000-0002-8301-5536']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "## D. Leer los jsons\n",
    "######################\n",
    "\n",
    "# 1. Leer los jsons y guardarlos en un dataframe\n",
    "df_renacyt= pd.read_parquet(os.path.join(os.getcwd(),'outputs','parquets','renacyt.parquet'))\n",
    "df_renacyt = df_renacyt[df_renacyt['orcid'].notnull()]\n",
    "df_renacyt = df_renacyt[df_renacyt['orcid'] != 'nan']\n",
    "df_renacyt = df_renacyt[df_renacyt['orcid'] != 'None']\n",
    "df_renacyt = df_renacyt[df_renacyt['orcid'] != '']\n",
    "df_renacyt['orcid'] = df_renacyt['orcid'].astype(str)\n",
    "\n",
    "# 2. Generar lista de urls a partir de ['ctiVitae']\n",
    "urls = []\n",
    "orcirds = df_renacyt['orcid'].tolist()\n",
    "for orcid in orcirds:\n",
    "    url = f'https://orcid.org/{orcid}'\n",
    "    urls.append(url)\n",
    "\n",
    "#urls = list(set(urls))\n",
    "print(f'Se generaron {len(urls)} urls')\n",
    "\n",
    "urls = urls[0:3]\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se inicia el servidor en Mac o Linux\n",
      "Usando el chromedriver_path: /Users/nahumfg/Projects/GitHubProjects/RenacytScraper/chromedriver/darwin/chromedriver\n",
      "1. https://orcid.org/0000-0003-1583-7113\n",
      "2. https://orcid.org/0000-0001-9740-5490\n",
      "3. https://orcid.org/0000-0002-8301-5536\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "## E. Ejecutar\n",
    "######################\n",
    "\n",
    "# 1. Iniciar el driver, el servidor proxy y el proxy\n",
    "driver, server, proxy = get_chrome_driver(chromedriver_path=CHROMEDRIVER_PATH, print_view=PRINT_VIEW, headless=HEADLESS)\n",
    "\n",
    "# 2. Iterar sobre las urls\n",
    "i = 0\n",
    "for url in urls: \n",
    "    # A. Iniciar har\n",
    "    start_har(proxy, 'renacyt_profile')\n",
    "    \n",
    "    # B. Ingresar a la url\n",
    "    driver.get(url)\n",
    "    print(f'{i+1}. {url}')\n",
    "\n",
    "    # C. Sí i==0, aceptar cookies\n",
    "    if i == 0:\n",
    "        find_element_and_click(driver, 'id', 'onetrust-accept-btn-handler')\n",
    "\n",
    "    # D. Obtener el har\n",
    "    time.sleep(3)\n",
    "    har = proxy.har\n",
    "\n",
    "    # E. Guardar publicaciones\n",
    "    j = 0\n",
    "    for entrie in har.get('log').get('entries'):\n",
    "        string_content = entrie.get('response').get('content').get('text')\n",
    "        if '{\"title\":' in str(string_content) and '\"assertionOriginOrcid\"' in str(string_content) and '\"assertionOriginClientId\"' in str(string_content):\n",
    "            data_list = json.loads(string_content)\n",
    "            #data_list = str(string_content)\n",
    "            with open(os.path.join(os.getcwd(),'outputs','jsons','orcid_title','title_' + str(i).zfill(2) + str(j).zfill(2) + '.json'), 'w') as json_file:\n",
    "                json.dump(data_list, json_file, indent=4)\n",
    "        j += 1\n",
    "\n",
    "    # j = 0\n",
    "    # for entrie in har.get('log').get('entries'):\n",
    "    #     #string_content = entrie.get('response').get('content').get('text')\n",
    "    #     #data_list = json.loads(string_content)\n",
    "    #     data_list = str(entrie)\n",
    "    #     with open(os.path.join(os.getcwd(),'outputs','jsons','orcid','orcid_' + str(i).zfill(2) + str(j).zfill(2) + '.json'), 'w') as json_file:\n",
    "    #         json.dump(data_list, json_file, indent=4)\n",
    "    #         j += 1\n",
    "\n",
    "    # F. Actualizar el contador\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se eliminaron los archivos bmp.log y server.log\n"
     ]
    }
   ],
   "source": [
    "stop_chrome_driver(driver, server, proxy)\n",
    "\n",
    "# Eliminar los archivos bmp.log y server.log\n",
    "try:\n",
    "    os.remove('bmp.log')\n",
    "    os.remove('server.log')\n",
    "    print(\"Se eliminaron los archivos bmp.log y server.log\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
